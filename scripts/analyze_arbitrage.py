#!/usr/bin/env python3
"""
å¥—åˆ©ä¿¡å·åˆ†æè„šæœ¬ï¼šåŸºäºå·²è½ç›˜çš„ orderbook å¿«ç…§ä¸å¸‚åœºå…ƒæ•°æ®ï¼Œ
è®¡ç®— Up/Down äºŒå…ƒå¸‚åœºçš„ midã€spreadã€sum_ask/sum_bidï¼Œå¹¶æ£€æµ‹å¥—åˆ©æœºä¼šã€‚

äºŒå…ƒå¸‚åœºç†è®ºï¼šUp + Down = 1ã€‚
- è‹¥ best_ask_Up + best_ask_Down < 1 - é˜ˆå€¼ï¼šä¹°å…¥ä¸¤è¾¹å¯é”åˆ©ï¼ˆä¹°åŒå¥—åˆ©ï¼‰ã€‚
- è‹¥ best_bid_Up + best_bid_Down > 1 + é˜ˆå€¼ï¼šå–å‡ºä¸¤è¾¹å¯é”åˆ©ï¼ˆå–åŒå¥—åˆ©ï¼‰ã€‚

ç”¨æ³•:
  python scripts/analyze_arbitrage.py [--data-dir DATA_DIR] [--slug SLUG] [--output CSV_PATH] [--threshold 0.01]
"""
from __future__ import annotations

import argparse
import json
import sys
from pathlib import Path

import pandas as pd
import httpx

# å…¼å®¹ä»é¡¹ç›®æ ¹æˆ– scripts ç›®å½•è¿è¡Œ
PROJECT_ROOT = Path(__file__).resolve().parent.parent
if str(PROJECT_ROOT) not in sys.path:
    sys.path.insert(0, str(PROJECT_ROOT))

try:
    from src.config import load_config
except ImportError:
    load_config = None


def _ensure_data_dir(data_dir: Path) -> None:
    if not data_dir.is_dir():
        raise FileNotFoundError(f"Data directory not found: {data_dir}")


def load_market_meta(data_dir: Path, slug: str) -> dict:
    """åŠ è½½å•ä¸ªå¸‚åœºçš„å…ƒæ•°æ®ï¼Œè¿”å› slug, token_ids, outcomes ç­‰ã€‚"""
    path = data_dir / "markets" / f"meta_{slug}.json"
    if not path.exists():
        raise FileNotFoundError(f"Market meta not found: {path}")
    with open(path, encoding="utf-8") as f:
        return json.load(f)


def list_slugs_from_meta(data_dir: Path) -> list[str]:
    """ä» data_dir/markets/meta_*.json åˆ—å‡ºæ‰€æœ‰ btc-updown-5m çš„ slugã€‚"""
    meta_dir = data_dir / "markets"
    if not meta_dir.is_dir():
        return []
    slugs = []
    for p in meta_dir.glob("meta_btc-updown-5m-*.json"):
        # æ’é™¤ test
        name = p.stem.replace("meta_", "")
        if "test" in name.lower():
            continue
        slugs.append(name)
    return sorted(slugs)


def _price_from_level(level) -> float:
    if isinstance(level, dict):
        return float(level.get("price", 0) or 0)
    if hasattr(level, "__len__") and len(level) >= 1:
        return float(level[0])
    return 0.0


def _best_bid_ask(bids: list, asks: list) -> tuple[float, float]:
    """ä» snapshot çš„ bids/asks åˆ—è¡¨å–æœ€ä½³ä¹°ä¸€/å–ä¸€ã€‚å­˜å‚¨å¯èƒ½ä¸º bids å‡åºã€asks é™åºï¼Œæ•…å–æœ€é«˜ä¹°ä»·ä¸æœ€ä½å–ä»·ã€‚"""
    best_bid = 0.0
    best_ask = 1.0
    try:
        bid_list = list(bids) if bids is not None else []
        if bid_list:
            prices = [_price_from_level(x) for x in bid_list]
            best_bid = max(prices)
    except (TypeError, ValueError):
        pass
    try:
        ask_list = list(asks) if asks is not None else []
        if ask_list:
            prices = [_price_from_level(x) for x in ask_list]
            best_ask = min(prices)
    except (TypeError, ValueError):
        pass
    return best_bid, best_ask


def load_snapshots_for_slug(data_dir: Path, slug: str, max_files: int | None = None) -> pd.DataFrame:
    """åŠ è½½è¯¥ slug ä¸‹æ‰€æœ‰ orderbook å¿«ç…§ parquetï¼Œåˆå¹¶ä¸ºä¸€å¼ è¡¨ã€‚"""
    snap_dir = data_dir / "orderbook" / "snapshots" / slug
    if not snap_dir.is_dir():
        return pd.DataFrame()
    files = sorted(snap_dir.glob("*.parquet"))
    if not files:
        return pd.DataFrame()
    if max_files is not None:
        files = files[: max_files]
    dfs = [pd.read_parquet(p) for p in files]
    out = pd.concat(dfs, ignore_index=True)
    # ä¿è¯ asset_id ä¸ºå­—ç¬¦ä¸²ï¼Œä¾¿äºä¸ meta çš„ token_ids åŒ¹é…
    if "asset_id" in out.columns:
        out["asset_id"] = out["asset_id"].astype(str).str.strip()
    # ä¸¢å¼ƒ bids/asks ä¸ºç©ºæˆ–æ— æ•ˆçš„è¡Œï¼Œé¿å…æ±¡æŸ“ best_bid/best_ask
    def _has_valid_book(books):
        if books is None or (isinstance(books, float) and pd.isna(books)):
            return False
        try:
            L = list(books)
            return len(L) > 0
        except (TypeError, ValueError):
            return False

    mask = out.apply(lambda r: _has_valid_book(r.get("bids")) and _has_valid_book(r.get("asks")), axis=1)
    out = out.loc[mask].copy()
    return out


def build_asset_to_outcome(meta: dict) -> dict[str, str]:
    """token_ids ä¸ outcomes é¡ºåºå¯¹åº”ï¼Œè¿”å› asset_id -> 'Up'|'Down'ã€‚"""
    token_ids = meta.get("token_ids") or []
    outcomes = meta.get("outcomes") or ["Up", "Down"]
    return dict(zip(token_ids, outcomes[: len(token_ids)]))


def run_arbitrage_analysis(
    data_dir: Path,
    slug: str,
    *,
    buy_threshold: float = 0.99,
    sell_threshold: float = 1.01,
    max_files: int | None = None,
) -> pd.DataFrame:
    """
    å¯¹æŒ‡å®š slug åšå¥—åˆ©åˆ†æï¼šåˆå¹¶åŒä¸€ ts_ms ä¸‹ä¸¤ä¸ª asset çš„ç›˜å£ï¼Œè®¡ç®— mid/spread ä¸ sum_ask/sum_bidã€‚
    è¿”å›æ¯æ—¶åˆ»ä¸€è¡Œçš„åˆ†æç»“æœ DataFrameã€‚
    """
    meta = load_market_meta(data_dir, slug)
    asset_to_outcome = build_asset_to_outcome(meta)
    if len(asset_to_outcome) != 2:
        raise ValueError(f"Expected 2 tokens for slug {slug}, got {len(asset_to_outcome)}")

    df = load_snapshots_for_slug(data_dir, slug, max_files=max_files)
    if df.empty:
        return pd.DataFrame()

    # è§£æ best bid / best ask
    def row_best_bid_ask(row):
        bids = row["bids"] if isinstance(row["bids"], list) else []
        asks = row["asks"] if isinstance(row["asks"], list) else []
        b, a = _best_bid_ask(bids, asks)
        return pd.Series({"best_bid": b, "best_ask": a})

    df[["best_bid", "best_ask"]] = df.apply(row_best_bid_ask, axis=1)
    # ä¸ meta çš„ token_idsï¼ˆå­—ç¬¦ä¸²ï¼‰ä¸€è‡´
    df["outcome"] = df["asset_id"].map(asset_to_outcome)

    # æŒ‰ ts_ms å¯¹é½ï¼šåŒä¸€æ—¶åˆ»ä¸¤ä¸ª outcome å„ä¸€è¡Œï¼Œpivot æˆä¸€è¡Œä¸¤åˆ—
    by_ts = df.groupby("ts_ms")
    rows = []
    for ts_ms, grp in by_ts:
        if grp.shape[0] != 2:
            continue
        up_row = grp[grp["outcome"] == "Up"]
        down_row = grp[grp["outcome"] == "Down"]
        if up_row.empty or down_row.empty:
            continue
        up_row, down_row = up_row.iloc[0], down_row.iloc[0]
        best_bid_up = float(up_row["best_bid"])
        best_ask_up = float(up_row["best_ask"])
        best_bid_down = float(down_row["best_bid"])
        best_ask_down = float(down_row["best_ask"])

        mid_up = (best_bid_up + best_ask_up) / 2 if (best_bid_up + best_ask_up) > 0 else 0.0
        mid_down = (best_bid_down + best_ask_down) / 2 if (best_bid_down + best_ask_down) > 0 else 0.0
        spread_up = best_ask_up - best_bid_up if best_ask_up > best_bid_up else 0.0
        spread_down = best_ask_down - best_bid_down if best_ask_down > best_bid_down else 0.0

        sum_ask = best_ask_up + best_ask_down
        sum_bid = best_bid_up + best_bid_down

        buy_both = sum_ask < buy_threshold
        sell_both = sum_bid > sell_threshold

        rows.append({
            "slug": slug,
            "ts_ms": ts_ms,
            "best_bid_up": best_bid_up,
            "best_ask_up": best_ask_up,
            "best_bid_down": best_bid_down,
            "best_ask_down": best_ask_down,
            "mid_up": mid_up,
            "mid_down": mid_down,
            "spread_up": spread_up,
            "spread_down": spread_down,
            "sum_bid": sum_bid,
            "sum_ask": sum_ask,
            "buy_both_opportunity": buy_both,
            "sell_both_opportunity": sell_both,
        })

    if not rows:
        return pd.DataFrame()
    return pd.DataFrame(rows)


def send_arbitrage_signals_to_discord(
    webhook_url: str,
    result: pd.DataFrame,
    buy_threshold: float,
    sell_threshold: float,
    *,
    max_opportunities_in_embed: int = 10,
) -> None:
    """å°†å¥—åˆ©ä¿¡å·æ±‡æ€»å‘é€åˆ° Discord webhookã€‚"""
    opportunities = result[
        result["buy_both_opportunity"] | result["sell_both_opportunity"]
    ].copy()
    if opportunities.empty:
        return

    n_buy = int(result["buy_both_opportunity"].sum())
    n_sell = int(result["sell_both_opportunity"].sum())
    slugs = result["slug"].unique().tolist()

    def _ts_fmt(ts_ms):
        try:
            from datetime import datetime
            return datetime.utcfromtimestamp(int(ts_ms) / 1000).strftime("%H:%M:%S")
        except Exception:
            return str(ts_ms)

    fields = [
        {"name": "å¸‚åœº (slug)", "value": ", ".join(slugs[:5]) + (" ..." if len(slugs) > 5 else ""), "inline": False},
        {"name": "ä¹°åŒå¥—åˆ© (sum_ask < {:.3f})".format(buy_threshold), "value": f"**{n_buy}** æ¬¡", "inline": True},
        {"name": "å–åŒå¥—åˆ© (sum_bid > {:.3f})".format(sell_threshold), "value": f"**{n_sell}** æ¬¡", "inline": True},
        {"name": "æ—¶é—´ç‚¹æ•°", "value": str(len(result)), "inline": True},
    ]

    # å–å‰å‡ æ¡æœºä¼šæ˜ç»†
    for _, row in opportunities.head(max_opportunities_in_embed).iterrows():
        kind = "ä¹°åŒ" if row["buy_both_opportunity"] else "å–åŒ"
        ts_str = _ts_fmt(row["ts_ms"])
        val = f"sum_ask={row['sum_ask']:.4f} sum_bid={row['sum_bid']:.4f}"
        fields.append({"name": f"{kind} @ {ts_str} ({row['slug']})", "value": val, "inline": False})

    body = {
        "embeds": [
            {
                "title": "ğŸ”” Polymarket å¥—åˆ©ä¿¡å·",
                "description": "BTC 5min Up/Down å¸‚åœºæ£€æµ‹åˆ°å¥—åˆ©æœºä¼šã€‚",
                "color": 0x00FF00 if (n_buy or n_sell) else 0x808080,
                "fields": fields,
            }
        ]
    }

    try:
        with httpx.Client(timeout=10.0) as client:
            r = client.post(webhook_url, json=body)
            r.raise_for_status()
    except Exception as e:
        print(f"Discord webhook å‘é€å¤±è´¥: {e}", file=sys.stderr)


def main() -> int:
    parser = argparse.ArgumentParser(
        description="Polymarket BTC 5min å¥—åˆ©ä¿¡å·åˆ†æï¼šåŸºäº orderbook å¿«ç…§è®¡ç®— mid/spread ä¸ä¹°åŒ/å–åŒå¥—åˆ©æœºä¼šã€‚"
    )
    parser.add_argument("--data-dir", type=Path, default=None, help="æ•°æ®ç›®å½•ï¼Œé»˜è®¤ä½¿ç”¨ config æˆ– data/")
    parser.add_argument("--slug", type=str, default=None, help="æŒ‡å®šå¸‚åœº slugï¼›ä¸æŒ‡å®šåˆ™åˆ†ææ‰€æœ‰å·²æœ‰å¿«ç…§çš„ btc-updown-5m å¸‚åœº")
    parser.add_argument("--output", "-o", type=Path, default=None, help="å°†åˆ†æç»“æœå†™å…¥ CSV")
    parser.add_argument("--threshold", type=float, default=0.01, help="å¥—åˆ©é˜ˆå€¼ï¼šä¹°åŒä¸º sum_ask < (1-threshold)ï¼Œå–åŒä¸º sum_bid > (1+threshold)")
    parser.add_argument("--summary-only", action="store_true", help="åªæ‰“å°æ±‡æ€»ç»Ÿè®¡ï¼Œä¸è¾“å‡ºæ¯æ—¶åˆ»æ˜ç»†")
    parser.add_argument("--max-files", type=int, default=None, help="æ¯ä¸ªå¸‚åœºæœ€å¤šåŠ è½½çš„ parquet æ–‡ä»¶æ•°ï¼ˆç”¨äºè°ƒè¯•ï¼‰")
    parser.add_argument("--discord-webhook", type=str, default=None, help="Discord webhook URLï¼Œå¥—åˆ©æœºä¼šå°†å‘é€åˆ°æ­¤é¢‘é“ï¼›ä¹Ÿå¯è®¾ç½®ç¯å¢ƒå˜é‡ DISCORD_WEBHOOK_URL æˆ– config ä¸­ discord_webhook_url")
    args = parser.parse_args()

    data_dir = args.data_dir
    if data_dir is None and load_config is not None:
        cfg = load_config()
        data_dir = Path(cfg.get("data_dir", PROJECT_ROOT / "data"))
    if data_dir is None:
        data_dir = PROJECT_ROOT / "data"
    data_dir = Path(data_dir)
    _ensure_data_dir(data_dir)

    buy_threshold = 1.0 - args.threshold
    sell_threshold = 1.0 + args.threshold

    if args.slug:
        slugs = [args.slug]
        for s in slugs:
            if not (data_dir / "markets" / f"meta_{s}.json").exists():
                print(f"Error: meta not found for slug {args.slug}", file=sys.stderr)
                return 1
    else:
        slugs = list_slugs_from_meta(data_dir)
        # åªä¿ç•™æœ‰å¿«ç…§æ•°æ®çš„ slug
        slugs = [s for s in slugs if (data_dir / "orderbook" / "snapshots" / s).is_dir()]
        if not slugs:
            print("No btc-updown-5m slugs with snapshot data found.", file=sys.stderr)
            return 1

    all_dfs: list[pd.DataFrame] = []
    for slug in slugs:
        try:
            df = run_arbitrage_analysis(
                data_dir,
                slug,
                buy_threshold=buy_threshold,
                sell_threshold=sell_threshold,
                max_files=args.max_files,
            )
            if not df.empty:
                all_dfs.append(df)
        except Exception as e:
            print(f"Skip {slug}: {e}", file=sys.stderr)

    if not all_dfs:
        print("No snapshot data could be analyzed.", file=sys.stderr)
        return 1

    result = pd.concat(all_dfs, ignore_index=True)
    result = result.sort_values("ts_ms").reset_index(drop=True)

    # æ±‡æ€»
    n = len(result)
    n_buy = result["buy_both_opportunity"].sum()
    n_sell = result["sell_both_opportunity"].sum()
    print("=== å¥—åˆ©ä¿¡å·åˆ†ææ±‡æ€» ===")
    print(f"æ•°æ®ç›®å½•: {data_dir}")
    print(f"å¸‚åœº( slug ): {result['slug'].unique().tolist()}")
    print(f"æ—¶é—´ç‚¹æ•°: {n}")
    print(f"ä¹°åŒå¥—åˆ©æœºä¼š (sum_ask < {buy_threshold:.3f}): {int(n_buy)} æ¬¡")
    print(f"å–åŒå¥—åˆ©æœºä¼š (sum_bid > {sell_threshold:.3f}): {int(n_sell)} æ¬¡")
    print(f"sum_ask  Min={result['sum_ask'].min():.4f}  Mean={result['sum_ask'].mean():.4f}  Max={result['sum_ask'].max():.4f}")
    print(f"sum_bid  Min={result['sum_bid'].min():.4f}  Mean={result['sum_bid'].mean():.4f}  Max={result['sum_bid'].max():.4f}")

    if not args.summary_only:
        print("\n--- å‰ 20 æ¡æ˜ç»† ---")
        print(result.head(20).to_string())

    if args.output:
        args.output.parent.mkdir(parents=True, exist_ok=True)
        result.to_csv(args.output, index=False)
        print(f"\nå·²å†™å…¥: {args.output}")

    # Discord é€šçŸ¥ï¼šæœ‰å¥—åˆ©æœºä¼šä¸”é…ç½®äº† webhook æ—¶å‘é€
    discord_url = args.discord_webhook
    if not discord_url and load_config is not None:
        cfg = load_config()
        discord_url = (cfg.get("discord_webhook_url") or "").strip()
    if discord_url and (n_buy > 0 or n_sell > 0):
        send_arbitrage_signals_to_discord(
            discord_url, result, buy_threshold, sell_threshold
        )
        print("å·²å‘ Discord å‘é€å¥—åˆ©ä¿¡å·ã€‚")

    return 0


if __name__ == "__main__":
    sys.exit(main())
